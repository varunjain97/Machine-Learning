{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['email', 'label'], dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'https://github.com/varunjain97/Machine-Learning/raw/master/spam_or_not_spam.csv')\n",
    "dataset .columns #Index(['email', 'label'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape  #(3000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "email  1\n",
      "label  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nemail  1\\nlabel  0\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (pd.DataFrame(dataset.isnull().sum()))\n",
    "'''\n",
    "email  1\n",
    "label  0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       date wed NUMBER aug NUMBER NUMBER NUMBER NUMBE...\n",
       "1       artin a posted tassos papadopoulos the greek s...\n",
       "2       an threatens explosion in moscow thursday augu...\n",
       "3       lez the virus that won t die already the most ...\n",
       "4       in adding cream to spaghetti carbonara which h...\n",
       "                              ...                        \n",
       "2995    abc s good morning america ranks it the NUMBER...\n",
       "2996    hyperlink hyperlink hyperlink let mortgage len...\n",
       "2997    thank you for shopping with us gifts for all o...\n",
       "2998    the famous ebay marketing e course learn to se...\n",
       "2999    hello this is chinese traditional 子 件 NUMBER世 ...\n",
       "Name: email, Length: 2999, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['email'].map(lambda email: email[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['email']=dataset['email'].map(lambda email: email[1:])\n",
    "dataset['email'] = dataset['email'].map(lambda email:re.sub('[^a-zA-Z0-9]+', ' ',email)).apply(lambda x: (x.lower()).split())\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [date, wed, number, aug, number, number, numbe...\n",
       "1       [artin, a, posted, tassos, papadopoulos, the, ...\n",
       "2       [an, threatens, explosion, in, moscow, thursda...\n",
       "3       [lez, the, virus, that, won, t, die, already, ...\n",
       "4       [in, adding, cream, to, spaghetti, carbonara, ...\n",
       "                              ...                        \n",
       "2995    [abc, s, good, morning, america, ranks, it, th...\n",
       "2996    [hyperlink, hyperlink, hyperlink, let, mortgag...\n",
       "2997    [thank, you, for, shopping, with, us, gifts, f...\n",
       "2998    [the, famous, ebay, marketing, e, course, lear...\n",
       "2999    [hello, this, is, chinese, traditional, number...\n",
       "Name: email, Length: 2999, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=dataset['email'].apply(lambda text_list:' '.join(list(map(lambda word:ps.stem(word),(list(filter(\n",
    "    lambda email:email not in set(stopwords.words('english')),text_list)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus.values).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes classifier to the Training set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "classifier.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[504   4]\n",
      " [  3  89]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConfusion Matrix\\narray([[863,  11],\\n       [  1, 264]])\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "'''\n",
    "Confusion Matrix\n",
    "array([[504,  4],\n",
    "       [  3, 89]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883333333333333\n",
      "593\n"
     ]
    }
   ],
   "source": [
    "#this function computes subset accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred)) #0.988333333333\n",
    "print(accuracy_score(y_test, y_pred,normalize=False)) #593"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
